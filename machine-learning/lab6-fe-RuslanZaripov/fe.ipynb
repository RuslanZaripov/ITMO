{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "Perform text preprocessing, remove unnecessary information\n",
    "\n",
    "---"
   ],
   "metadata": {
    "id": "NdPO5ERslUSp"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\""
   ],
   "metadata": {
    "id": "6T7TeCXbJMKm",
    "ExecuteTime": {
     "end_time": "2023-05-31T20:15:59.366405900Z",
     "start_time": "2023-05-31T20:15:59.335113600Z"
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "rOHlc5V3dy45",
    "outputId": "26836419-8177-4e39-dc88-d6e7dad11560",
    "ExecuteTime": {
     "end_time": "2023-05-31T20:20:23.078078300Z",
     "start_time": "2023-05-31T20:20:15.466240Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rusla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 500)\n"
     ]
    },
    {
     "data": {
      "text/plain": "     class                                               text\n4456   ham  storm msg wen u lift phne u say hello u knw wt...\n690   spam       forward pleas call immedi urgent messag wait\n944    ham  also ive sorta blown coupl time recent id rath...\n3768   ham                             sir goodmorn free call\n1189   ham             come alivebett correct good look figur\n4437   ham  housemaid murder coz man murder ltgt th januar...\n3587  spam  hot n horni will live local text repli hear st...\n1982   ham  sorri ill call later meet thing relat trade pl...\n2038   ham                                     oh sorri pleas\n2078   ham  hey hunonbus goin meet want go meal donyt feel...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4456</th>\n      <td>ham</td>\n      <td>storm msg wen u lift phne u say hello u knw wt...</td>\n    </tr>\n    <tr>\n      <th>690</th>\n      <td>spam</td>\n      <td>forward pleas call immedi urgent messag wait</td>\n    </tr>\n    <tr>\n      <th>944</th>\n      <td>ham</td>\n      <td>also ive sorta blown coupl time recent id rath...</td>\n    </tr>\n    <tr>\n      <th>3768</th>\n      <td>ham</td>\n      <td>sir goodmorn free call</td>\n    </tr>\n    <tr>\n      <th>1189</th>\n      <td>ham</td>\n      <td>come alivebett correct good look figur</td>\n    </tr>\n    <tr>\n      <th>4437</th>\n      <td>ham</td>\n      <td>housemaid murder coz man murder ltgt th januar...</td>\n    </tr>\n    <tr>\n      <th>3587</th>\n      <td>spam</td>\n      <td>hot n horni will live local text repli hear st...</td>\n    </tr>\n    <tr>\n      <th>1982</th>\n      <td>ham</td>\n      <td>sorri ill call later meet thing relat trade pl...</td>\n    </tr>\n    <tr>\n      <th>2038</th>\n      <td>ham</td>\n      <td>oh sorri pleas</td>\n    </tr>\n    <tr>\n      <th>2078</th>\n      <td>ham</td>\n      <td>hey hunonbus goin meet want go meal donyt feel...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "df = pd.read_table('SMS.tsv')\n",
    "\n",
    "df = df.sample(n=1000, random_state=0)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(regex, '', text)\n",
    "\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    text = ' '.join([stemmer.stem(word) for word in text.split()])\n",
    "    \n",
    "    return text\n",
    "\n",
    "df['text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=500)\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['class'] = label_encoder.fit_transform(df['class'])\n",
    "y = df['class']\n",
    "\n",
    "df.head(10)"
   ],
   "metadata": {
    "id": "9D-Nmweu7v22",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "outputId": "280a62ad-2d6d-400e-fd2a-94f1d895fde0",
    "ExecuteTime": {
     "end_time": "2023-05-31T20:20:32.489073Z",
     "start_time": "2023-05-31T20:20:32.391760400Z"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "      class                                               text\n4456      0  storm msg wen u lift phne u say hello u knw wt...\n690       1       forward pleas call immedi urgent messag wait\n944       0  also ive sorta blown coupl time recent id rath...\n3768      0                             sir goodmorn free call\n1189      0             come alivebett correct good look figur\n4437      0  housemaid murder coz man murder ltgt th januar...\n3587      1  hot n horni will live local text repli hear st...\n1982      0  sorri ill call later meet thing relat trade pl...\n2038      0                                     oh sorri pleas\n2078      0  hey hunonbus goin meet want go meal donyt feel...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4456</th>\n      <td>0</td>\n      <td>storm msg wen u lift phne u say hello u knw wt...</td>\n    </tr>\n    <tr>\n      <th>690</th>\n      <td>1</td>\n      <td>forward pleas call immedi urgent messag wait</td>\n    </tr>\n    <tr>\n      <th>944</th>\n      <td>0</td>\n      <td>also ive sorta blown coupl time recent id rath...</td>\n    </tr>\n    <tr>\n      <th>3768</th>\n      <td>0</td>\n      <td>sir goodmorn free call</td>\n    </tr>\n    <tr>\n      <th>1189</th>\n      <td>0</td>\n      <td>come alivebett correct good look figur</td>\n    </tr>\n    <tr>\n      <th>4437</th>\n      <td>0</td>\n      <td>housemaid murder coz man murder ltgt th januar...</td>\n    </tr>\n    <tr>\n      <th>3587</th>\n      <td>1</td>\n      <td>hot n horni will live local text repli hear st...</td>\n    </tr>\n    <tr>\n      <th>1982</th>\n      <td>0</td>\n      <td>sorri ill call later meet thing relat trade pl...</td>\n    </tr>\n    <tr>\n      <th>2038</th>\n      <td>0</td>\n      <td>oh sorri pleas</td>\n    </tr>\n    <tr>\n      <th>2078</th>\n      <td>0</td>\n      <td>hey hunonbus goin meet want go meal donyt feel...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "Embedded FE\n",
    "\n",
    "RidgeCV\n",
    "\n",
    "---"
   ],
   "metadata": {
    "id": "QJ7UgVCTkiA4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "ridge = RidgeCV()\n",
    "ridge.fit(X, y)\n",
    "\n",
    "feature_coefs = zip(vectorizer.get_feature_names_out(), ridge.coef_)\n",
    "\n",
    "sorted_features_embedded = sorted(feature_coefs, key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "for feature, coef in sorted_features_embedded[:30]:\n",
    "    print(f\"Feature: {feature:20} Coefficient: {coef:.5f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XVyQzQp6BBQr",
    "outputId": "82266709-3ebe-4b38-b098-51230506aedc",
    "ExecuteTime": {
     "end_time": "2023-05-31T20:21:10.545260100Z",
     "start_time": "2023-05-31T20:21:10.325615600Z"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: txt                  Coefficient: 1.04421\n",
      "Feature: servic               Coefficient: 0.72743\n",
      "Feature: claim                Coefficient: 0.57399\n",
      "Feature: contact              Coefficient: 0.57327\n",
      "Feature: mobil                Coefficient: 0.56827\n",
      "Feature: latest               Coefficient: 0.54384\n",
      "Feature: win                  Coefficient: 0.54348\n",
      "Feature: secret               Coefficient: 0.51059\n",
      "Feature: text                 Coefficient: 0.49402\n",
      "Feature: award                Coefficient: 0.46896\n",
      "Feature: nokia                Coefficient: 0.46248\n",
      "Feature: call                 Coefficient: 0.45917\n",
      "Feature: uk                   Coefficient: 0.45722\n",
      "Feature: free                 Coefficient: 0.44202\n",
      "Feature: stop                 Coefficient: 0.43524\n",
      "Feature: voucher              Coefficient: 0.43345\n",
      "Feature: tone                 Coefficient: 0.42937\n",
      "Feature: new                  Coefficient: 0.41546\n",
      "Feature: custom               Coefficient: 0.41165\n",
      "Feature: rate                 Coefficient: 0.41069\n",
      "Feature: repli                Coefficient: 0.40081\n",
      "Feature: landlin              Coefficient: 0.39778\n",
      "Feature: chat                 Coefficient: 0.38638\n",
      "Feature: line                 Coefficient: 0.37635\n",
      "Feature: pobox                Coefficient: 0.36433\n",
      "Feature: poli                 Coefficient: 0.35618\n",
      "Feature: video                Coefficient: 0.35410\n",
      "Feature: pmin                 Coefficient: 0.35364\n",
      "Feature: urgent               Coefficient: 0.34649\n",
      "Feature: box                  Coefficient: 0.34459\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_intercept(X):\n",
    "    intercept = np.ones((X.shape[0], 1))\n",
    "    return np.concatenate((intercept, X.toarray()), axis=1)\n",
    "\n",
    "def ridge_regression(X, y, alpha):\n",
    "    XtX = X.T.dot(X)\n",
    "    XtX_alpha = XtX + alpha * np.identity(XtX.shape[0])\n",
    "    XtX_inv = np.linalg.inv(XtX_alpha)\n",
    "    Xty = X.T.dot(y)\n",
    "    w = XtX_inv.dot(Xty)\n",
    "    return w[1:], w[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T20:23:25.116903700Z",
     "start_time": "2023-05-31T20:23:25.085193100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "alpha = 1.0\n",
    "\n",
    "coefficients, intercept = ridge_regression(add_intercept(X), y, alpha)\n",
    "\n",
    "feature_coefs = zip(vectorizer.get_feature_names_out(), coefficients)\n",
    "\n",
    "sorted_features_embedded = sorted(feature_coefs, key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "for feature, coef in sorted_features_embedded[:30]:\n",
    "    print(f\"Feature: {feature:20} Coefficient: {coef:.5f}\")\n",
    "\n",
    "print(f\"Intercept: {intercept:.5f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oGALzr2TCT4x",
    "outputId": "a5810d6f-2d22-44aa-fa0c-6987d4652fed",
    "ExecuteTime": {
     "end_time": "2023-05-31T20:23:35.758668200Z",
     "start_time": "2023-05-31T20:23:35.664542900Z"
    }
   },
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: txt                  Coefficient: 1.04442\n",
      "Feature: servic               Coefficient: 0.72760\n",
      "Feature: claim                Coefficient: 0.57412\n",
      "Feature: contact              Coefficient: 0.57334\n",
      "Feature: mobil                Coefficient: 0.56845\n",
      "Feature: latest               Coefficient: 0.54394\n",
      "Feature: win                  Coefficient: 0.54371\n",
      "Feature: secret               Coefficient: 0.51062\n",
      "Feature: text                 Coefficient: 0.49421\n",
      "Feature: award                Coefficient: 0.46912\n",
      "Feature: nokia                Coefficient: 0.46255\n",
      "Feature: call                 Coefficient: 0.45953\n",
      "Feature: uk                   Coefficient: 0.45725\n",
      "Feature: free                 Coefficient: 0.44219\n",
      "Feature: stop                 Coefficient: 0.43546\n",
      "Feature: voucher              Coefficient: 0.43354\n",
      "Feature: tone                 Coefficient: 0.42948\n",
      "Feature: new                  Coefficient: 0.41562\n",
      "Feature: custom               Coefficient: 0.41183\n",
      "Feature: rate                 Coefficient: 0.41080\n",
      "Feature: repli                Coefficient: 0.40094\n",
      "Feature: landlin              Coefficient: 0.39793\n",
      "Feature: chat                 Coefficient: 0.38653\n",
      "Feature: line                 Coefficient: 0.37652\n",
      "Feature: pobox                Coefficient: 0.36435\n",
      "Feature: poli                 Coefficient: 0.35629\n",
      "Feature: video                Coefficient: 0.35410\n",
      "Feature: pmin                 Coefficient: 0.35375\n",
      "Feature: urgent               Coefficient: 0.34663\n",
      "Feature: box                  Coefficient: 0.34472\n",
      "Intercept: 0.06627\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "Wrapper FE\n",
    "\n",
    "Backward elimination\n",
    "\n",
    "---"
   ],
   "metadata": {
    "id": "i9HRHQOzk3C3"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "def backward_elimination(data, target, significance_level=0.05):\n",
    "    features = data.columns.tolist()\n",
    "\n",
    "    while len(features) > 0:\n",
    "        features_with_constant = sm.add_constant(data[features])\n",
    "\n",
    "        p_values = sm.OLS(target, features_with_constant).fit().pvalues[1:]\n",
    "        \n",
    "        if p_values.max() >= significance_level:\n",
    "            excluded_feature = p_values.idxmax()\n",
    "            features.remove(excluded_feature)\n",
    "            print(f'Len of features {len(features)}, removing {excluded_feature}')\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return features"
   ],
   "metadata": {
    "id": "gXC9tc9j2nhw",
    "ExecuteTime": {
     "end_time": "2023-05-31T20:25:19.143617100Z",
     "start_time": "2023-05-31T20:25:17.368197600Z"
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_vectorized = pd.DataFrame(X.todense(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "backward_selected_features = backward_elimination(df_vectorized, list(y))\n",
    "\n",
    "sorted_backward_features = sorted(backward_selected_features, key=lambda x: df_vectorized[x].std(), reverse=True)\n",
    "\n",
    "print(\"Top 30 Backward Selected Features:\")\n",
    "print(sorted_backward_features[:30])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hyqdx4n03jim",
    "outputId": "a1c33d8e-c811-4e62-f2a5-73da8e930e06",
    "ExecuteTime": {
     "end_time": "2023-05-31T20:27:53.877633600Z",
     "start_time": "2023-05-31T20:25:23.689350700Z"
    }
   },
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of features 499, removing last\n",
      "Len of features 498, removing kid\n",
      "Len of features 497, removing thank\n",
      "Len of features 496, removing player\n",
      "Len of features 495, removing though\n",
      "Len of features 494, removing prob\n",
      "Len of features 493, removing yes\n",
      "Len of features 492, removing start\n",
      "Len of features 491, removing awesom\n",
      "Len of features 490, removing tmr\n",
      "Len of features 489, removing enough\n",
      "Len of features 488, removing lunch\n",
      "Len of features 487, removing lar\n",
      "Len of features 486, removing today\n",
      "Len of features 485, removing smoke\n",
      "Len of features 484, removing de\n",
      "Len of features 483, removing thought\n",
      "Len of features 482, removing havent\n",
      "Len of features 481, removing face\n",
      "Len of features 480, removing frm\n",
      "Len of features 479, removing half\n",
      "Len of features 478, removing fetch\n",
      "Len of features 477, removing got\n",
      "Len of features 476, removing da\n",
      "Len of features 475, removing recent\n",
      "Len of features 474, removing suppos\n",
      "Len of features 473, removing lot\n",
      "Len of features 472, removing school\n",
      "Len of features 471, removing us\n",
      "Len of features 470, removing correct\n",
      "Len of features 469, removing ish\n",
      "Len of features 468, removing pick\n",
      "Len of features 467, removing move\n",
      "Len of features 466, removing go\n",
      "Len of features 465, removing wk\n",
      "Len of features 464, removing drug\n",
      "Len of features 463, removing dis\n",
      "Len of features 462, removing speak\n",
      "Len of features 461, removing princess\n",
      "Len of features 460, removing everi\n",
      "Len of features 459, removing man\n",
      "Len of features 458, removing near\n",
      "Len of features 457, removing shall\n",
      "Len of features 456, removing brother\n",
      "Len of features 455, removing come\n",
      "Len of features 454, removing save\n",
      "Len of features 453, removing eat\n",
      "Len of features 452, removing shit\n",
      "Len of features 451, removing point\n",
      "Len of features 450, removing drive\n",
      "Len of features 449, removing show\n",
      "Len of features 448, removing fuck\n",
      "Len of features 447, removing yup\n",
      "Len of features 446, removing put\n",
      "Len of features 445, removing someth\n",
      "Len of features 444, removing sat\n",
      "Len of features 443, removing thk\n",
      "Len of features 442, removing done\n",
      "Len of features 441, removing th\n",
      "Len of features 440, removing mani\n",
      "Len of features 439, removing rock\n",
      "Len of features 438, removing envelop\n",
      "Len of features 437, removing lei\n",
      "Len of features 436, removing anyway\n",
      "Len of features 435, removing someon\n",
      "Len of features 434, removing sch\n",
      "Len of features 433, removing dunno\n",
      "Len of features 432, removing ticket\n",
      "Len of features 431, removing long\n",
      "Len of features 430, removing abl\n",
      "Len of features 429, removing wit\n",
      "Len of features 428, removing safe\n",
      "Len of features 427, removing believ\n",
      "Len of features 426, removing ah\n",
      "Len of features 425, removing fren\n",
      "Len of features 424, removing shop\n",
      "Len of features 423, removing wif\n",
      "Len of features 422, removing earli\n",
      "Len of features 421, removing came\n",
      "Len of features 420, removing hear\n",
      "Len of features 419, removing haha\n",
      "Len of features 418, removing dat\n",
      "Len of features 417, removing guess\n",
      "Len of features 416, removing okay\n",
      "Len of features 415, removing huh\n",
      "Len of features 414, removing cheer\n",
      "Len of features 413, removing til\n",
      "Len of features 412, removing camera\n",
      "Len of features 411, removing yo\n",
      "Len of features 410, removing better\n",
      "Len of features 409, removing feel\n",
      "Len of features 408, removing light\n",
      "Len of features 407, removing peopl\n",
      "Len of features 406, removing ive\n",
      "Len of features 405, removing bad\n",
      "Len of features 404, removing shower\n",
      "Len of features 403, removing ever\n",
      "Len of features 402, removing pain\n",
      "Len of features 401, removing plz\n",
      "Len of features 400, removing abt\n",
      "Len of features 399, removing worri\n",
      "Len of features 398, removing walk\n",
      "Len of features 397, removing soon\n",
      "Len of features 396, removing yeah\n",
      "Len of features 395, removing night\n",
      "Len of features 394, removing touch\n",
      "Len of features 393, removing later\n",
      "Len of features 392, removing number\n",
      "Len of features 391, removing realli\n",
      "Len of features 390, removing big\n",
      "Len of features 389, removing togeth\n",
      "Len of features 388, removing time\n",
      "Len of features 387, removing xmas\n",
      "Len of features 386, removing let\n",
      "Len of features 385, removing holiday\n",
      "Len of features 384, removing dun\n",
      "Len of features 383, removing place\n",
      "Len of features 382, removing hop\n",
      "Len of features 381, removing den\n",
      "Len of features 380, removing wat\n",
      "Len of features 379, removing busi\n",
      "Len of features 378, removing fun\n",
      "Len of features 377, removing anoth\n",
      "Len of features 376, removing may\n",
      "Len of features 375, removing hav\n",
      "Len of features 374, removing hurt\n",
      "Len of features 373, removing msg\n",
      "Len of features 372, removing saturday\n",
      "Len of features 371, removing good\n",
      "Len of features 370, removing deliv\n",
      "Len of features 369, removing still\n",
      "Len of features 368, removing hey\n",
      "Len of features 367, removing alright\n",
      "Len of features 366, removing hospit\n",
      "Len of features 365, removing think\n",
      "Len of features 364, removing offici\n",
      "Len of features 363, removing hour\n",
      "Len of features 362, removing your\n",
      "Len of features 361, removing pay\n",
      "Len of features 360, removing order\n",
      "Len of features 359, removing chang\n",
      "Len of features 358, removing never\n",
      "Len of features 357, removing yet\n",
      "Len of features 356, removing first\n",
      "Len of features 355, removing earlier\n",
      "Len of features 354, removing probabl\n",
      "Len of features 353, removing stuff\n",
      "Len of features 352, removing break\n",
      "Len of features 351, removing cheap\n",
      "Len of features 350, removing search\n",
      "Len of features 349, removing told\n",
      "Len of features 348, removing alreadi\n",
      "Len of features 347, removing reach\n",
      "Len of features 346, removing keep\n",
      "Len of features 345, removing paper\n",
      "Len of features 344, removing dedic\n",
      "Len of features 343, removing know\n",
      "Len of features 342, removing england\n",
      "Len of features 341, removing bed\n",
      "Len of features 340, removing money\n",
      "Len of features 339, removing age\n",
      "Len of features 338, removing trip\n",
      "Len of features 337, removing problem\n",
      "Len of features 336, removing mail\n",
      "Len of features 335, removing there\n",
      "Len of features 334, removing kiss\n",
      "Len of features 333, removing whenev\n",
      "Len of features 332, removing cash\n",
      "Len of features 331, removing went\n",
      "Len of features 330, removing wen\n",
      "Len of features 329, removing how\n",
      "Len of features 328, removing dad\n",
      "Len of features 327, removing say\n",
      "Len of features 326, removing question\n",
      "Len of features 325, removing nice\n",
      "Len of features 324, removing pub\n",
      "Len of features 323, removing alway\n",
      "Len of features 322, removing excus\n",
      "Len of features 321, removing leh\n",
      "Len of features 320, removing nite\n",
      "Len of features 319, removing grl\n",
      "Len of features 318, removing late\n",
      "Len of features 317, removing wake\n",
      "Len of features 316, removing anyth\n",
      "Len of features 315, removing lor\n",
      "Len of features 314, removing yrs\n",
      "Len of features 313, removing also\n",
      "Len of features 312, removing countri\n",
      "Len of features 311, removing sure\n",
      "Len of features 310, removing xxx\n",
      "Len of features 309, removing prize\n",
      "Len of features 308, removing wish\n",
      "Len of features 307, removing read\n",
      "Len of features 306, removing gud\n",
      "Len of features 305, removing pm\n",
      "Len of features 304, removing guy\n",
      "Len of features 303, removing gift\n",
      "Len of features 302, removing bslvyl\n",
      "Len of features 301, removing slowli\n",
      "Len of features 300, removing prefer\n",
      "Len of features 299, removing wont\n",
      "Len of features 298, removing right\n",
      "Len of features 297, removing moment\n",
      "Len of features 296, removing leav\n",
      "Len of features 295, removing amp\n",
      "Len of features 294, removing find\n",
      "Len of features 293, removing import\n",
      "Len of features 292, removing town\n",
      "Len of features 291, removing hous\n",
      "Len of features 290, removing want\n",
      "Len of features 289, removing shes\n",
      "Len of features 288, removing sleep\n",
      "Len of features 287, removing buy\n",
      "Len of features 286, removing tell\n",
      "Len of features 285, removing slept\n",
      "Len of features 284, removing gettin\n",
      "Len of features 283, removing that\n",
      "Len of features 282, removing book\n",
      "Len of features 281, removing mind\n",
      "Len of features 280, removing stori\n",
      "Len of features 279, removing person\n",
      "Len of features 278, removing day\n",
      "Len of features 277, removing forget\n",
      "Len of features 276, removing birthday\n",
      "Len of features 275, removing thing\n",
      "Len of features 274, removing doesnt\n",
      "Len of features 273, removing class\n",
      "Len of features 272, removing mah\n",
      "Len of features 271, removing work\n",
      "Len of features 270, removing liao\n",
      "Len of features 269, removing world\n",
      "Len of features 268, removing smile\n",
      "Len of features 267, removing run\n",
      "Len of features 266, removing simpl\n",
      "Len of features 265, removing quit\n",
      "Len of features 264, removing cos\n",
      "Len of features 263, removing avail\n",
      "Len of features 262, removing morn\n",
      "Len of features 261, removing what\n",
      "Len of features 260, removing love\n",
      "Len of features 259, removing make\n",
      "Len of features 258, removing much\n",
      "Len of features 257, removing everyth\n",
      "Len of features 256, removing wanna\n",
      "Len of features 255, removing hi\n",
      "Len of features 254, removing meet\n",
      "Len of features 253, removing need\n",
      "Len of features 252, removing look\n",
      "Len of features 251, removing pa\n",
      "Len of features 250, removing meant\n",
      "Len of features 249, removing great\n",
      "Len of features 248, removing kate\n",
      "Len of features 247, removing girlfrnd\n",
      "Len of features 246, removing knw\n",
      "Len of features 245, removing girl\n",
      "Len of features 244, removing gal\n",
      "Len of features 243, removing tomorrow\n",
      "Len of features 242, removing tire\n",
      "Len of features 241, removing special\n",
      "Len of features 240, removing noe\n",
      "Len of features 239, removing sent\n",
      "Len of features 238, removing rememb\n",
      "Len of features 237, removing job\n",
      "Len of features 236, removing life\n",
      "Len of features 235, removing ok\n",
      "Len of features 234, removing happen\n",
      "Len of features 233, removing date\n",
      "Len of features 232, removing pretti\n",
      "Len of features 231, removing lesson\n",
      "Len of features 230, removing record\n",
      "Len of features 229, removing mistak\n",
      "Len of features 228, removing one\n",
      "Len of features 227, removing parent\n",
      "Len of features 226, removing didnt\n",
      "Len of features 225, removing plan\n",
      "Len of features 224, removing collect\n",
      "Len of features 223, removing get\n",
      "Len of features 222, removing dear\n",
      "Len of features 221, removing talk\n",
      "Len of features 220, removing bus\n",
      "Len of features 219, removing slow\n",
      "Len of features 218, removing tonight\n",
      "Len of features 217, removing might\n",
      "Len of features 216, removing lucki\n",
      "Len of features 215, removing actual\n",
      "Len of features 214, removing tot\n",
      "Len of features 213, removing even\n",
      "Len of features 212, removing sale\n",
      "Len of features 211, removing mobileupd\n",
      "Len of features 210, removing coz\n",
      "Len of features 209, removing reason\n",
      "Len of features 208, removing tcs\n",
      "Len of features 207, removing lol\n",
      "Len of features 206, removing could\n",
      "Len of features 205, removing friend\n",
      "Len of features 204, removing type\n",
      "Len of features 203, removing use\n",
      "Len of features 202, removing bt\n",
      "Len of features 201, removing song\n",
      "Len of features 200, removing statement\n",
      "Len of features 199, removing sorri\n",
      "Len of features 198, removing tel\n",
      "Len of features 197, removing readi\n",
      "Len of features 196, removing sub\n",
      "Len of features 195, removing pic\n",
      "Len of features 194, removing test\n",
      "Len of features 193, removing take\n",
      "Len of features 192, removing nd\n",
      "Len of features 191, removing heart\n",
      "Len of features 190, removing sweet\n",
      "Len of features 189, removing pleas\n",
      "Len of features 188, removing would\n",
      "Len of features 187, removing tomo\n",
      "Len of features 186, removing end\n",
      "Len of features 185, removing mate\n",
      "Len of features 184, removing best\n",
      "Len of features 183, removing babi\n",
      "Len of features 182, removing im\n",
      "Len of features 181, removing cool\n",
      "Len of features 180, removing remov\n",
      "Len of features 179, removing chanc\n",
      "Len of features 178, removing tri\n",
      "Len of features 177, removing jus\n",
      "Len of features 176, removing wait\n",
      "Len of features 175, removing cant\n",
      "Len of features 174, removing finish\n",
      "Len of features 173, removing home\n",
      "Len of features 172, removing bit\n",
      "Len of features 171, removing mean\n",
      "Len of features 170, removing sea\n",
      "Len of features 169, removing ask\n",
      "Len of features 168, removing care\n",
      "Len of features 167, removing ur\n",
      "Len of features 166, removing an\n",
      "Len of features 165, removing month\n",
      "Len of features 164, removing till\n",
      "Len of features 163, removing hope\n",
      "Len of features 162, removing deal\n",
      "Len of features 161, removing expir\n",
      "Len of features 160, removing code\n",
      "Len of features 159, removing identifi\n",
      "Len of features 158, removing rental\n",
      "Len of features 157, removing camcord\n",
      "Len of features 156, removing updat\n",
      "Len of features 155, removing rington\n",
      "Len of features 154, removing gonna\n",
      "Len of features 153, removing car\n",
      "Len of features 152, removing watch\n",
      "Len of features 151, removing movi\n",
      "Len of features 150, removing tv\n",
      "Len of features 149, removing like\n",
      "Len of features 148, removing within\n",
      "Len of features 147, removing ring\n",
      "Len of features 146, removing bring\n",
      "Len of features 145, removing food\n",
      "Len of features 144, removing real\n",
      "Len of features 143, removing ya\n",
      "Len of features 142, removing luv\n",
      "Len of features 141, removing happi\n",
      "Len of features 140, removing network\n",
      "Len of features 139, removing min\n",
      "Len of features 138, removing muz\n",
      "Len of features 137, removing said\n",
      "Len of features 136, removing dont\n",
      "Len of features 135, removing oh\n",
      "Len of features 134, removing noth\n",
      "Len of features 133, removing download\n",
      "Len of features 132, removing receiv\n",
      "Len of features 131, removing select\n",
      "Len of features 130, removing drink\n",
      "Len of features 129, removing mayb\n",
      "Len of features 128, removing hrs\n",
      "Len of features 127, removing easi\n",
      "Len of features 126, removing dream\n",
      "Len of features 125, removing stay\n",
      "Len of features 124, removing hello\n",
      "Len of features 123, removing pobox\n",
      "Len of features 122, removing auction\n",
      "Len of features 121, removing sort\n",
      "Len of features 120, removing well\n",
      "Len of features 119, removing guarante\n",
      "Len of features 118, removing land\n",
      "Len of features 117, removing facebook\n",
      "Len of features 116, removing sms\n",
      "Len of features 115, removing forgot\n",
      "Len of features 114, removing bday\n",
      "Len of features 113, removing way\n",
      "Len of features 112, removing week\n",
      "Len of features 111, removing enjoy\n",
      "Len of features 110, removing credit\n",
      "Len of features 109, removing back\n",
      "Len of features 108, removing pls\n",
      "Len of features 107, removing dog\n",
      "Len of features 106, removing poli\n",
      "Len of features 105, removing cost\n",
      "Len of features 104, removing wid\n",
      "Len of features 103, removing weekend\n",
      "Len of features 102, removing wonder\n",
      "Len of features 101, removing nation\n",
      "Len of features 100, removing year\n",
      "Len of features 99, removing room\n",
      "Len of features 98, removing miss\n",
      "Len of features 97, removing give\n",
      "Len of features 96, removing goe\n",
      "Len of features 95, removing around\n",
      "Len of features 94, removing boy\n",
      "Len of features 93, removing babe\n",
      "Len of features 92, removing line\n",
      "Len of features 91, removing visit\n",
      "Top 30 Backward Selected Features:\n",
      "['call', 'ill', 'free', 'ltgt', 'send', 'see', 'messag', 'text', 'phone', 'sir', 'stop', 'new', 'check', 'name', 'repli', 'mobil', 'servic', 'txt', 'help', 'per', 'nokia', 'next', 'wan', 'chat', 'play', 'custom', 'game', 'pmin', 'award', 'contact']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "Filter FE\n",
    "\n",
    "Коэффициент корреляции (Пирсона или Спирмена)\n",
    "\n",
    "---"
   ],
   "metadata": {
    "id": "bSh7Ay-ilCsV"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def my_pearsonr(x, y):\n",
    "    if len(x) != len(y):\n",
    "        raise ValueError(\"Input arrays must have the same length.\")\n",
    "    \n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "\n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "\n",
    "    x_std = np.std(x)\n",
    "    y_std = np.std(y)\n",
    "\n",
    "    covariance = np.mean((x - x_mean) * (y - y_mean))\n",
    "\n",
    "    correlation = covariance / (x_std * y_std)\n",
    "\n",
    "    return correlation"
   ],
   "metadata": {
    "id": "N0_tUiaMoBza",
    "ExecuteTime": {
     "end_time": "2023-05-31T20:28:20.964795300Z",
     "start_time": "2023-05-31T20:28:20.934517500Z"
    }
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "correlations = []\n",
    "for feature_idx in range(X.shape[1]):\n",
    "    feature = X[:, feature_idx].toarray().flatten()\n",
    "    correlation = my_pearsonr(feature, y)\n",
    "    correlations.append(correlation)\n",
    "\n",
    "features_df = pd.DataFrame({'Feature': vectorizer.get_feature_names_out(), 'Correlation': correlations})\n",
    "\n",
    "features_df = features_df.sort_values(by='Correlation', ascending=False)\n",
    "\n",
    "features_df.head(30)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 991
    },
    "id": "y3-_l5sMmkLn",
    "outputId": "5d535c9e-946f-4889-b9f1-0deec3afa02f",
    "ExecuteTime": {
     "end_time": "2023-05-31T20:28:35.132000800Z",
     "start_time": "2023-05-31T20:28:34.965607400Z"
    }
   },
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "      Feature  Correlation\n445       txt     0.435425\n138      free     0.339904\n252     mobil     0.330881\n49       call     0.314752\n64      claim     0.306839\n277     nokia     0.264016\n322     prize     0.254495\n23      award     0.252392\n476       win     0.246747\n369    servic     0.246364\n399      stop     0.246179\n413      text     0.243605\n39        box     0.242046\n434      tone     0.238021\n160  guarante     0.230250\n344     repli     0.229025\n70    contact     0.228732\n450    urgent     0.228052\n331      rate     0.219160\n271       new     0.218598\n221      line     0.217016\n312     pobox     0.215963\n409       tcs     0.203439\n280     offer     0.203260\n204   landlin     0.202682\n209    latest     0.202431\n80     custom     0.200063\n52     camera     0.192853\n50    camcord     0.189258\n316       ppm     0.189193",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature</th>\n      <th>Correlation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>445</th>\n      <td>txt</td>\n      <td>0.435425</td>\n    </tr>\n    <tr>\n      <th>138</th>\n      <td>free</td>\n      <td>0.339904</td>\n    </tr>\n    <tr>\n      <th>252</th>\n      <td>mobil</td>\n      <td>0.330881</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>call</td>\n      <td>0.314752</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>claim</td>\n      <td>0.306839</td>\n    </tr>\n    <tr>\n      <th>277</th>\n      <td>nokia</td>\n      <td>0.264016</td>\n    </tr>\n    <tr>\n      <th>322</th>\n      <td>prize</td>\n      <td>0.254495</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>award</td>\n      <td>0.252392</td>\n    </tr>\n    <tr>\n      <th>476</th>\n      <td>win</td>\n      <td>0.246747</td>\n    </tr>\n    <tr>\n      <th>369</th>\n      <td>servic</td>\n      <td>0.246364</td>\n    </tr>\n    <tr>\n      <th>399</th>\n      <td>stop</td>\n      <td>0.246179</td>\n    </tr>\n    <tr>\n      <th>413</th>\n      <td>text</td>\n      <td>0.243605</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>box</td>\n      <td>0.242046</td>\n    </tr>\n    <tr>\n      <th>434</th>\n      <td>tone</td>\n      <td>0.238021</td>\n    </tr>\n    <tr>\n      <th>160</th>\n      <td>guarante</td>\n      <td>0.230250</td>\n    </tr>\n    <tr>\n      <th>344</th>\n      <td>repli</td>\n      <td>0.229025</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>contact</td>\n      <td>0.228732</td>\n    </tr>\n    <tr>\n      <th>450</th>\n      <td>urgent</td>\n      <td>0.228052</td>\n    </tr>\n    <tr>\n      <th>331</th>\n      <td>rate</td>\n      <td>0.219160</td>\n    </tr>\n    <tr>\n      <th>271</th>\n      <td>new</td>\n      <td>0.218598</td>\n    </tr>\n    <tr>\n      <th>221</th>\n      <td>line</td>\n      <td>0.217016</td>\n    </tr>\n    <tr>\n      <th>312</th>\n      <td>pobox</td>\n      <td>0.215963</td>\n    </tr>\n    <tr>\n      <th>409</th>\n      <td>tcs</td>\n      <td>0.203439</td>\n    </tr>\n    <tr>\n      <th>280</th>\n      <td>offer</td>\n      <td>0.203260</td>\n    </tr>\n    <tr>\n      <th>204</th>\n      <td>landlin</td>\n      <td>0.202682</td>\n    </tr>\n    <tr>\n      <th>209</th>\n      <td>latest</td>\n      <td>0.202431</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>custom</td>\n      <td>0.200063</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>camera</td>\n      <td>0.192853</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>camcord</td>\n      <td>0.189258</td>\n    </tr>\n    <tr>\n      <th>316</th>\n      <td>ppm</td>\n      <td>0.189193</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "Python Libraries feature selection \n",
    "\n",
    "---"
   ],
   "metadata": {
    "id": "VLXS0j6upz0J"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "selectors = [\n",
    "    (\"SelectKBest\", SelectKBest(score_func=chi2, k=30)),\n",
    "    (\"SelectFromModel\", SelectFromModel(estimator=RandomForestClassifier(random_state=0), max_features=30)),\n",
    "    (\"RFE\", RFE(LogisticRegression(), n_features_to_select=30))\n",
    "]\n",
    "\n",
    "for name, selector in selectors:\n",
    "    X_new = selector.fit_transform(X, y)\n",
    "\n",
    "    selected_features = selector.get_support(indices=True)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    print(f\"Selected features using {name}:\")\n",
    "    print(feature_names[selected_features])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VREbT-KuxM1b",
    "outputId": "6f29d8fa-6e0d-44d8-a6bd-8dd9aa44fa5c",
    "ExecuteTime": {
     "end_time": "2023-05-31T20:29:04.825891300Z",
     "start_time": "2023-05-31T20:28:57.862541800Z"
    }
   },
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features using SelectKBest:\n",
      "['award' 'box' 'call' 'camera' 'claim' 'contact' 'custom' 'deliveri'\n",
      " 'free' 'guarante' 'landlin' 'latest' 'line' 'mobil' 'new' 'nokia' 'offer'\n",
      " 'pmin' 'pobox' 'poli' 'prize' 'rate' 'repli' 'servic' 'stop' 'text'\n",
      " 'tone' 'txt' 'urgent' 'win']\n",
      "Selected features using SelectFromModel:\n",
      "['award' 'box' 'call' 'chat' 'claim' 'contact' 'custom' 'free' 'landlin'\n",
      " 'latest' 'line' 'messag' 'mobil' 'new' 'nokia' 'offer' 'pmin' 'pobox'\n",
      " 'prize' 'rate' 'repli' 'servic' 'stop' 'text' 'tone' 'txt' 'ur' 'urgent'\n",
      " 'voucher' 'win']\n",
      "Selected features using RFE:\n",
      "['award' 'box' 'call' 'chat' 'claim' 'contact' 'custom' 'free' 'ill'\n",
      " 'landlin' 'latest' 'line' 'min' 'mobil' 'new' 'nokia' 'pobox' 'privat'\n",
      " 'prize' 'rate' 'repli' 'servic' 'stop' 'text' 'tone' 'txt' 'ur' 'urgent'\n",
      " 'voucher' 'win']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "Compare classification before and after applying feature selection methods\n",
    "\n",
    "---"
   ],
   "metadata": {
    "id": "yq2VOMF29xHK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ],
   "metadata": {
    "id": "ZGedmVPhFVz3",
    "ExecuteTime": {
     "end_time": "2023-05-31T20:29:14.816797600Z",
     "start_time": "2023-05-31T20:29:14.789540500Z"
    }
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "models = [\n",
    "    (\"SVC\", SVC()),\n",
    "    (\"DecisionTreeClassifier\", DecisionTreeClassifier()),\n",
    "    (\"KNeighborsClassifier\", KNeighborsClassifier()),\n",
    "]\n",
    "\n",
    "def performance():\n",
    "  print(\"Before:\")\n",
    "  calc_acc(X_train, X_test)\n",
    "\n",
    "  for name_sel, selector in selectors:\n",
    "    X_train_new = selector.fit_transform(X_train, y_train)\n",
    "\n",
    "    X_test_new = selector.transform(X_test)\n",
    "\n",
    "    print(f\"\\nAfter for {name_sel} method:\")\n",
    "    calc_acc(X_train_new, X_test_new)\n",
    "\n",
    "def calc_acc(X_train, X_test):\n",
    "  for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_before = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred_before)\n",
    "    print(f\"Accuracy for {name}: {accuracy}\")\n",
    "\n",
    "performance()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eI24U_9uGVbn",
    "outputId": "f7ae6c16-d2d7-411c-a001-640fc8cc864c",
    "ExecuteTime": {
     "end_time": "2023-05-31T20:29:21.844180Z",
     "start_time": "2023-05-31T20:29:15.849319300Z"
    }
   },
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "Accuracy for SVC: 0.9533333333333334\n",
      "Accuracy for DecisionTreeClassifier: 0.9233333333333333\n",
      "Accuracy for KNeighborsClassifier: 0.86\n",
      "\n",
      "After for SelectKBest method:\n",
      "Accuracy for SVC: 0.95\n",
      "Accuracy for DecisionTreeClassifier: 0.9266666666666666\n",
      "Accuracy for KNeighborsClassifier: 0.91\n",
      "\n",
      "After for SelectFromModel method:\n",
      "Accuracy for SVC: 0.94\n",
      "Accuracy for DecisionTreeClassifier: 0.9266666666666666\n",
      "Accuracy for KNeighborsClassifier: 0.91\n",
      "\n",
      "After for RFE method:\n",
      "Accuracy for SVC: 0.95\n",
      "Accuracy for DecisionTreeClassifier: 0.9166666666666666\n",
      "Accuracy for KNeighborsClassifier: 0.9\n"
     ]
    }
   ]
  }
 ]
}
