{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "XYNY_Vcb2Aul"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yG_n40gFzf9s",
    "ExecuteTime": {
     "end_time": "2023-05-04T14:45:07.388149100Z",
     "start_time": "2023-05-04T14:44:49.913178800Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "aavnuByVymwK",
    "ExecuteTime": {
     "end_time": "2023-05-04T14:45:07.431883700Z",
     "start_time": "2023-05-04T14:45:07.421927100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = open('shakespeare.txt', 'rb').read().decode(encoding='utf-8')\n",
    "\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Duhg9NrUymwO",
    "ExecuteTime": {
     "end_time": "2023-05-04T14:45:07.448326400Z",
     "start_time": "2023-05-04T14:45:07.425478800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1115394 characters\n",
      "65 unique characters\n"
     ]
    }
   ],
   "source": [
    "print(f'Length of text: {len(text)} characters')\n",
    "\n",
    "vocab = sorted(set(text))\n",
    "print(f'{len(vocab)} unique characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6GMlCe3qzaL9",
    "ExecuteTime": {
     "end_time": "2023-05-04T14:45:07.865714500Z",
     "start_time": "2023-05-04T14:45:07.425478800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(3,), dtype=int64, numpy=array([40, 41, 42], dtype=int64)>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert from tokens to character IDs:\n",
    "ids_from_chars = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)\n",
    "\n",
    "ids_from_chars(tf.strings.unicode_split('abc', input_encoding='UTF-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Wd2m3mqkDjRj",
    "ExecuteTime": {
     "end_time": "2023-05-04T14:45:07.895636500Z",
     "start_time": "2023-05-04T14:45:07.663324400Z"
    }
   },
   "outputs": [],
   "source": [
    "# recover readable strings from IDs:\n",
    "chars_from_ids = tf.keras.layers.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "w5apvBDn9Ind",
    "ExecuteTime": {
     "end_time": "2023-05-04T14:45:07.896606100Z",
     "start_time": "2023-05-04T14:45:07.697658800Z"
    }
   },
   "outputs": [],
   "source": [
    "def text_from_ids(m_ids):\n",
    "    return tf.strings.reduce_join(chars_from_ids(m_ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "UopbsKi88tm5",
    "ExecuteTime": {
     "end_time": "2023-05-04T14:45:07.897587Z",
     "start_time": "2023-05-04T14:45:07.709020500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'first citizen before we proceed any further hear me speak  all speak speak  first citizen you are all resolved rather to die than to famish  all resolved resolved  first citizen first you know caius marcius is chief enemy to the people  all we knowt '"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate text\n",
    "text = text.lower()\n",
    "\n",
    "import string\n",
    "text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "text = text.replace('\\n', ' ')\n",
    "\n",
    "text[:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1060997,), dtype=int64, numpy=array([45, 48, 57, ..., 53, 46,  2], dtype=int64)>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
    "all_ids"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T14:45:08.510059900Z",
     "start_time": "2023-05-04T14:45:07.731662Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qmxrYDCTy-eL",
    "ExecuteTime": {
     "end_time": "2023-05-04T14:45:08.576856300Z",
     "start_time": "2023-05-04T14:45:08.498033700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An iterable over the elements of the dataset, with their tensors converted to numpy arrays.\n",
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
    "ids_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cjH5v45-yqqH",
    "ExecuteTime": {
     "end_time": "2023-05-04T14:45:08.690667400Z",
     "start_time": "2023-05-04T14:45:08.527381200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f\n",
      "i\n",
      "r\n",
      "s\n",
      "t\n",
      " \n",
      "c\n",
      "i\n",
      "t\n",
      "i\n"
     ]
    }
   ],
   "source": [
    "for ids in ids_dataset.take(10):\n",
    "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "C-G2oaTxy6km",
    "ExecuteTime": {
     "end_time": "2023-05-04T14:45:08.692180200Z",
     "start_time": "2023-05-04T14:45:08.677285Z"
    }
   },
   "outputs": [],
   "source": [
    "seq_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "BpdjRO2CzOfZ",
    "ExecuteTime": {
     "end_time": "2023-05-04T14:45:09.599713700Z",
     "start_time": "2023-05-04T14:45:08.694155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'f' b'i' b'r' b's' b't' b' ' b'c' b'i' b't' b'i' b'z' b'e' b'n' b' '\n",
      " b'b' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o' b'c'\n",
      " b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h' b'e'\n",
      " b'r' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p' b'e' b'a'\n",
      " b'k' b' ' b' ' b'a' b'l' b'l' b' ' b's' b'p' b'e' b'a' b'k' b' ' b's'\n",
      " b'p' b'e' b'a' b'k' b' ' b' ' b'f' b'i' b'r' b's' b't' b' ' b'c' b'i'\n",
      " b't' b'i' b'z' b'e' b'n' b' ' b'y' b'o' b'u' b' ' b'a' b'r' b'e' b' '\n",
      " b'a' b'l' b'l']\n"
     ]
    }
   ],
   "source": [
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for seq in sequences.take(1):\n",
    "  print(chars_from_ids(seq).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "QO32cMWu4a06",
    "ExecuteTime": {
     "end_time": "2023-05-04T14:45:09.605690600Z",
     "start_time": "2023-05-04T14:45:09.094928200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'first citizen before we proceed any further hear me speak  all speak speak  first citizen you are all'\n",
      "b' resolved rather to die than to famish  all resolved resolved  first citizen first you know caius mar'\n",
      "b'cius is chief enemy to the people  all we knowt we knowt  first citizen let us kill him and well have'\n",
      "b' corn at our own price ist a verdict  all no more talking ont let it be done away away  second citize'\n",
      "b'n one word good citizens  first citizen we are accounted poor citizens the patricians good what autho'\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences.take(5):\n",
    "  print(text_from_ids(seq).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "9NGu-FkO_kYU",
    "ExecuteTime": {
     "end_time": "2023-05-04T14:45:09.605690600Z",
     "start_time": "2023-05-04T14:45:09.163621Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "B9iKPXkw5xwa",
    "ExecuteTime": {
     "end_time": "2023-05-04T14:45:09.607645300Z",
     "start_time": "2023-05-04T14:45:09.199942100Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "GNbw-iR0ymwj",
    "ExecuteTime": {
     "end_time": "2023-05-04T14:45:09.607645300Z",
     "start_time": "2023-05-04T14:45:09.310704800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : b'first citizen before we proceed any further hear me speak  all speak speak  first citizen you are al'\n",
      "Target: b'irst citizen before we proceed any further hear me speak  all speak speak  first citizen you are all'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
    "    print(\"Target:\", text_from_ids(target_example).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "p2pGotuNzf-S",
    "ExecuteTime": {
     "end_time": "2023-05-04T14:45:09.608619400Z",
     "start_time": "2023-05-04T14:45:09.473677Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE) # Creates a Dataset that prefetches elements from this dataset.\n",
    ")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "zHT8cLh7EAsg",
    "ExecuteTime": {
     "end_time": "2023-05-04T14:45:09.608619400Z",
     "start_time": "2023-05-04T14:45:09.528495Z"
    }
   },
   "outputs": [],
   "source": [
    "# Length of the vocabulary in StringLookup Layer\n",
    "vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "wj8HQ2w8z4iO",
    "ExecuteTime": {
     "end_time": "2023-05-04T14:45:09.619035800Z",
     "start_time": "2023-05-04T14:45:09.530010100Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__(self)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.LSTM(rnn_units, return_sequences=True, return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x = inputs\n",
    "        x = self.embedding(x, training=training)\n",
    "        if states is None:\n",
    "          states = self.lstm.get_initial_state(x)\n",
    "        x, state_h, state_c = self.lstm(x, initial_state=states, training=training)\n",
    "        x = self.dense(x, training=training)\n",
    "\n",
    "        if return_state:\n",
    "          return x, [state_h, state_c]\n",
    "        else:\n",
    "          return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "IX58Xj9z47Aw",
    "ExecuteTime": {
     "end_time": "2023-05-04T14:45:09.833467800Z",
     "start_time": "2023-05-04T14:45:09.577404700Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "C-_70kKAPrPU",
    "ExecuteTime": {
     "end_time": "2023-05-04T14:45:15.832096700Z",
     "start_time": "2023-05-04T14:45:09.690835700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "vPGmAAXmVLGC",
    "ExecuteTime": {
     "end_time": "2023-05-04T14:45:15.960968800Z",
     "start_time": "2023-05-04T14:45:15.835030800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  16896     \n",
      "                                                                 \n",
      " lstm (LSTM)                 multiple                  5246976   \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  67650     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,331,522\n",
      "Trainable params: 5,331,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "DDl1_Een6rL0",
    "ExecuteTime": {
     "end_time": "2023-05-04T14:45:15.962921300Z",
     "start_time": "2023-05-04T14:45:15.882834500Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "7yGBE2zxMMHs",
    "ExecuteTime": {
     "end_time": "2023-05-04T14:45:15.962921300Z",
     "start_time": "2023-05-04T14:45:15.916941100Z"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "UK-hmKjYVoll",
    "ExecuteTime": {
     "end_time": "2023-05-04T14:45:15.963895800Z",
     "start_time": "2023-05-04T14:45:15.929863600Z"
    }
   },
   "outputs": [],
   "source": [
    "# history = model.fit(dataset, epochs=EPOCHS)\n",
    "# model.save_weights('./mw.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "iSBU1tHmlUSs",
    "ExecuteTime": {
     "end_time": "2023-05-04T14:45:16.039630400Z",
     "start_time": "2023-05-04T14:45:15.950068200Z"
    }
   },
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "  def __init__(self, m_model, m_chars_from_ids, m_ids_from_chars, temperature=1.0):\n",
    "    super().__init__()\n",
    "    self.temperature = temperature\n",
    "    self.model = m_model\n",
    "    self.chars_from_ids = m_chars_from_ids\n",
    "    self.ids_from_chars = m_ids_from_chars\n",
    "\n",
    "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "    sparse_mask = tf.SparseTensor(\n",
    "        values=[-float('inf')]*len(skip_ids),\n",
    "        indices=skip_ids,\n",
    "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "    predicted_logits, states = self.model(inputs=input_ids, states=states, return_state=True)\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits / self.temperature\n",
    "    predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "    # Sample the output logits to generate token IDs.\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "    return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "fqMOuDutnOxK",
    "ExecuteTime": {
     "end_time": "2023-05-04T14:45:20.887962500Z",
     "start_time": "2023-05-04T14:45:15.958459600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "reload_model = Model(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)\n",
    "\n",
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = reload_model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
    "\n",
    "reload_model.load_weights(\"./mw3.h5\")\n",
    "\n",
    "one_step_model = OneStep(reload_model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ST7PSyk9t1mT",
    "ExecuteTime": {
     "end_time": "2023-05-04T14:56:15.589937700Z",
     "start_time": "2023-05-04T14:56:09.405544900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 5.986987 seconds\n",
      "________________________________________________________________________________\n",
      "\n",
      "\n",
      "ROMEO:\n",
      "Go, seve at her news into beheld the him\n",
      "And labbed the pay and saved his unlawful fed\n",
      "Murders not sent footing less. This is the sword:\n",
      "Yet yout persuasion bad it is not in.'\n",
      "\n",
      "Nurse:\n",
      "My lord, what false Ladys you be drawn'd sound?\n",
      "\n",
      "First Officer:\n",
      "Marry: masters! First.\n",
      "\n",
      "MERCUTIO:\n",
      "O, though they are fornick I had been enemies,\n",
      "An't. Inless a soar plainly bishopouse,\n",
      "Which almost Soliciar-sarricands, worthy, as they\n",
      "with those tongue, to turn thy chair her shed;\n",
      "Be-chasuded that thy schoop'd my brother\n",
      "With revenges diked thee on thy speech,\n",
      "In the peace to have him leave a value veil\n",
      "The vall of your majesty is almost,\n",
      "As dog into something be brief.\n",
      "\n",
      "LEONTES:\n",
      "Is it they gosset and fair son?\n",
      "Can you are well in Secanday? and the ream\n",
      "Luintle imina much flown as Capulet\n",
      "Fit for differences the patrenting sweets!\n",
      "\n",
      "ROMEO:\n",
      "Aufidius coriol-Bent for, it send\n",
      "How he indeed of death, conscienced no foot\n",
      "And courteous hurts for ever news.\n",
      "Proceedest three such a sea, with you;\n",
      "Were always feas\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "\n",
    "\n",
    "def timer(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.perf_counter()\n",
    "        print(f\"Elapsed time: {(end_time - start_time):.6f} seconds\\n\" + '_'*80 + '\\n\\n')\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@timer\n",
    "def text(next_char, states=None):\n",
    "    next_char = tf.constant([next_char])\n",
    "    result = [next_char]\n",
    "    for n in range(1000):\n",
    "        next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "        result.append(next_char)\n",
    "    return tf.strings.join(result)[0].numpy().decode('utf-8')\n",
    "\n",
    "print(text('ROMEO:'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T14:45:35.687040300Z",
     "start_time": "2023-05-04T14:45:32.921772800Z"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "text_generation.ipynb",
   "toc_visible": true,
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
